# -*- coding: utf-8 -*-
"""1M_Hypertuning_Combined1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sdOu6jCvrVBHsmlMO357gYriaS_wLgwZ
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from ast import literal_eval

ratings = pd.read_csv('/content/drive/MyDrive/OBJECTIVE 1/data/ratings.csv')
#users = pd.read_csv('/content/drive/MyDrive/Data/users.csv')
#movies = pd.read_csv('/content/drive/MyDrive/OBJECTIVE 1/data/100K/movies.csv',encoding='latin-1')
#tags = pd.read_csv('/content/drive/MyDrive/OBJECTIVE 1/data/100K/tags.csv',encoding='latin-1')

from google.colab import drive
drive.mount('/content/drive')

ratings.head()

"""Hypertuning"""

pip install scikit-surprise

from surprise import SVD, BaselineOnly, SVDpp, NMF, SlopeOne, CoClustering, Reader
from surprise import Dataset
from surprise.model_selection import cross_validate
from surprise.prediction_algorithms import KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore
from surprise import accuracy
from surprise.model_selection import train_test_split

import os

from surprise import BaselineOnly, Dataset, Reader
from surprise.model_selection import cross_validate

ratings.head()

reader = Reader(rating_scale=(1, 5))

data = Dataset.load_from_df(ratings[["UserID", "MovieID", "Rating"]], reader)

#file_path = os.path.expanduser("~/.surprise_data/ml-100k/ml-100k/u.data")

from surprise import NormalPredictor
from surprise.model_selection import GridSearchCV

algo = BaselineOnly()

test_rmse, test_mae, test_predictions, fit_time, test_time = recommendation(algo,trainset,testset)
print(fit_time)
print(test_time)

algo = SVD()

# Train the algorithm on the trainset, and predict ratings for the testset
algo.fit(trainset)
predictions = algo.test(testset)

accuracy.rmse(predictions)
accuracy.mae(predictions)
print("Done!")

algo = SVDpp()

# Train the algorithm on the trainset, and predict ratings for the testset
algo.fit(trainset)
predictions = algo.test(testset)

accuracy.rmse(predictions)
accuracy.mae(predictions)
print("Done!")

algo = NMF()

# Train the algorithm on the trainset, and predict ratings for the testset
algo.fit(trainset)
predictions = algo.test(testset)

accuracy.rmse(predictions)
accuracy.mae(predictions)
print("Done!")

"""SVD and SVDpp"""

#data = Dataset.load_builtin("ml-1m")

param_grid = {'n_factors':[50,100,150],'n_epochs':[20,30],  'lr_all':[0.005,0.01],'reg_all':[0.02,0.1]}

param_grid = {'n_factors':[25,50,100], 'n_epochs': [5, 10, 20], 'lr_all': [0.01, 0.02],
              'reg_all': [0.01,0.02]}
gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5)

gs.fit(data)

#best RMSE score
print(gs.best_score['rmse'])

#combination of parameters that gave the best RMSE score
print(gs.best_params['rmse'])

print(gs.best_score['rmse'])

print(gs.best_score['mae'])

"""Chaning number of neighbors for KNN"""

param_grid = {'k': [15, 20, 25, 30, 40, 50, 60]}

knnbasic_gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=5, n_jobs=5)
knnbasic_gs.fit(data)

knnmeans_gs = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse', 'mae'], cv=5, n_jobs=5)
knnmeans_gs.fit(data)

knnz_gs = GridSearchCV(KNNWithZScore, param_grid, measures=['rmse', 'mae'], cv=5, n_jobs=5)
knnz_gs.fit(data)

knnbaseline_gs = GridSearchCV(KNNBaseline, param_grid, measures=['rmse', 'mae'], cv=5, n_jobs=5)
knnbaseline_gs.fit(data)

knnbasic_gs.best_params['rmse']

x = [15, 20, 25, 30, 40, 50, 60]
y1 = knnbasic_gs.cv_results['mean_test_rmse']
y2 = knnbasic_gs.cv_results['mean_test_mae']

y3 = knnmeans_gs.cv_results['mean_test_rmse']
y4 = knnmeans_gs.cv_results['mean_test_mae']

y5 = knnz_gs.cv_results['mean_test_rmse']
y6 = knnz_gs.cv_results['mean_test_mae']

y7 = knnbaseline_gs.cv_results['mean_test_rmse']
y8 = knnbaseline_gs.cv_results['mean_test_mae']

y1,y2,y3,y4,y5,y6,y7,y8





